apiVersion: v1
kind: Pod
metadata:
    name: online-inference
    labels:
        app: online-inference
spec:
    containers:
        -   image: panda1987ds/online_inference:v0.1
            resources:
                requests:
                    memory: "64Mi"
                    cpu: "250m"
                limits:
                    memory: "128Mi"
                    cpu: "500m"
            livenessProbe:
                httpGet:
                    path: /touch
                    port: 8080
                initialDelaySeconds: 10
                periodSeconds: 5
            readinessProbe:
                httpGet:
                    path: /touch
                    port: 8080
                initialDelaySeconds: 10
                periodSeconds: 5
            name: online-inference
            ports:
                -   containerPort: 8080
